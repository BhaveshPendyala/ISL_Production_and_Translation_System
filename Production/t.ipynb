{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Initializing GeminiProcessor...\n",
      "ðŸ“„ Loaded sign words list.\n",
      "ðŸ“„ Loaded conversation history.\n",
      "â³ Waiting for WebSocket connection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-3 (run_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Final\\.venv\\Lib\\site-packages\\websockets\\asyncio\\client.py\", line 541, in __await_impl__\n",
      "    self.connection = await self.create_connection()\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Final\\.venv\\Lib\\site-packages\\websockets\\asyncio\\client.py\", line 467, in create_connection\n",
      "    _, connection = await loop.create_connection(factory, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1070, in create_connection\n",
      "    sock = await self._connect_sock(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 974, in _connect_sock\n",
      "    await self.sock_connect(sock, address)\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\selector_events.py\", line 638, in sock_connect\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 349, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\futures.py\", line 198, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Final\\.venv\\Lib\\site-packages\\websockets\\asyncio\\client.py\", line 539, in __await_impl__\n",
      "    async with asyncio_timeout(self.open_timeout):\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\timeouts.py\", line 115, in __aexit__\n",
      "    raise TimeoutError from exc_val\n",
      "TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"d:\\Final\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Temp\\ipykernel_3700\\2628489461.py\", line 233, in run_loop\n",
      "  File \"d:\\Final\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 279, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Temp\\ipykernel_3700\\2628489461.py\", line 236, in connect\n",
      "  File \"d:\\Final\\.venv\\Lib\\site-packages\\websockets\\asyncio\\client.py\", line 587, in __aenter__\n",
      "    return await self\n",
      "           ^^^^^^^^^^\n",
      "  File \"d:\\Final\\.venv\\Lib\\site-packages\\websockets\\asyncio\\client.py\", line 578, in __await_impl__\n",
      "    raise TimeoutError(\"timed out during opening handshake\") from exc\n",
      "TimeoutError: timed out during opening handshake\n"
     ]
    }
   ],
   "source": [
    "# === All-in-One Production App with Debugging ===\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import asyncio\n",
    "import json\n",
    "import base64\n",
    "import tkinter as tk\n",
    "from tkinter import Label, Button, Frame\n",
    "import pyttsx3\n",
    "import numpy as np\n",
    "import websockets\n",
    "import whisper\n",
    "import re\n",
    "from queue import Queue\n",
    "from datetime import datetime\n",
    "from scipy.io.wavfile import write\n",
    "import google.generativeai as genai\n",
    "import nest_asyncio\n",
    "import warnings\n",
    "import pyaudio\n",
    "import sys\n",
    "\n",
    "# === Setup ===\n",
    "nest_asyncio.apply()\n",
    "genai.configure(api_key=\"AIzaSyCK31ozj2CSPbb5tnvznQtzNxQPX1cjaS0\")\n",
    "\n",
    "MESSAGE_FILE = \"D:/Final/speechtotext/conversation_history.txt\"\n",
    "WORDS_FILE = \"D:/Final/speechtotext/words.txt\"\n",
    "KEYPOINTS_FOLDER = \"extracted_keypoints\"\n",
    "MERGED_OUTPUT_FILE = \"D:/Final/speechtotext/runtime_merged_keypoints.npy\"\n",
    "TRANSLATION_SERVER_URI = \"ws://192.168.84.139:8779\"\n",
    "\n",
    "is_muted = False  # Global mute state\n",
    "latest_spoken = \"\"\n",
    "speech_lock = threading.Lock()\n",
    "\n",
    "# === Gemini Processor ===\n",
    "class GeminiProcessor:\n",
    "    def __init__(self):\n",
    "        print(\"ðŸ”§ Initializing GeminiProcessor...\")\n",
    "        self.available_words = self.load_word_list(WORDS_FILE)\n",
    "        self.conversation_history = self.load_conversation_history()\n",
    "\n",
    "    def load_word_list(self, path):\n",
    "        try:\n",
    "            with open(path, \"r\") as f:\n",
    "                print(\"ðŸ“„ Loaded sign words list.\")\n",
    "                return {w.strip().lower() for w in f.readlines()}\n",
    "        except FileNotFoundError:\n",
    "            print(\"âš ï¸ Word list file not found!\")\n",
    "            return set()\n",
    "\n",
    "    def load_conversation_history(self):\n",
    "        try:\n",
    "            with open(MESSAGE_FILE, \"r\") as f:\n",
    "                print(\"ðŸ“„ Loaded conversation history.\")\n",
    "                return f.readlines()\n",
    "        except FileNotFoundError:\n",
    "            print(\"âš ï¸ Conversation history file not found!\")\n",
    "            return []\n",
    "\n",
    "    def append_to_history(self, text):\n",
    "        entry = f'normal_user:\"{text}\"\\n'\n",
    "        if entry not in self.conversation_history:\n",
    "            self.conversation_history.append(entry)\n",
    "            with open(MESSAGE_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(entry)\n",
    "            print(f\"ðŸ“ Appended to history: {entry.strip()}\")\n",
    "\n",
    "    def append_sign_user_response(self, response):\n",
    "        entry = f'sign_user: . \"{response}\"\\n'\n",
    "        if entry not in self.conversation_history:\n",
    "            self.conversation_history.append(entry)\n",
    "            with open(MESSAGE_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(entry)\n",
    "            print(f\"ðŸ“¥ Appended sign_user response: {entry.strip()}\")\n",
    "\n",
    "    def paraphrase(self, sentence):\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert in sign language translation. Your task is to rewrite the given sentence using ** words that have corresponding signs**, while preserving the original meaning.\n",
    "\n",
    "        ### **Instructions:**\n",
    "        1 Use Available Sign Words**: If a word from the input sentence exists in the **available sign words list**, retain it.\n",
    "        2 Modify Words for Sign Compatibility**:\n",
    "        - Convert plural words to singular (e.g., **cats â†’ cat**).\n",
    "        - Convert continuous tense to base form (e.g., **running â†’ run**, **doing â†’ do**).\n",
    "        - Reduce words to their simplest root form (e.g., **quickly â†’ quick**, **happily â†’ happy**).\n",
    "        3 Synonym Replacement**: If no direct match exists, replace the word with a synonym that is **available** in the sign words list.\n",
    "        4 Grammar Adaptation**: Restructure the sentence to match **sign language grammar**, making it concise while maintaining clarity.\n",
    "        5 Preserve Context**: Ensure the paraphrased sentence aligns with previous conversation history.\n",
    "        6 Output Format**: Return **only the final paraphrased sentence** without explanations.\n",
    "\n",
    "        ### **Available Sign Words**:\n",
    "        {', '.join(self.available_words)}\n",
    "\n",
    "        ### **Conversation Context**:\n",
    "        \"{''.join(self.conversation_history)}\"\n",
    "\n",
    "        ### **Input Sentence**:\n",
    "        \"{sentence}\"\n",
    "\n",
    "        ### **Paraphrased Sentence:**\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = genai.GenerativeModel(\"gemini-1.5-pro\").start_chat().send_message(prompt)\n",
    "            paraphrased = response.text.strip()\n",
    "            print(f\"ðŸ”„ Paraphrased: {paraphrased}\")\n",
    "            return paraphrased\n",
    "        except Exception as e:\n",
    "            print(\"âš ï¸ Gemini API Error:\", e)\n",
    "            return sentence\n",
    "\n",
    "# === Helpers ===\n",
    "def load_and_merge_keypoints(words, folder, output):\n",
    "    merged = []\n",
    "    for word in words:\n",
    "        clean = re.sub(r'\\W+', '', word)\n",
    "        path = os.path.join(folder, f\"{clean}.npy\")\n",
    "        if os.path.exists(path):\n",
    "            print(f\"âœ… Found keypoints for: {clean}\")\n",
    "            merged.append(np.load(path))\n",
    "        else:\n",
    "            print(f\"âš ï¸ Missing keypoints: {clean}.npy\")\n",
    "    if merged:\n",
    "        combined = np.vstack(merged)\n",
    "        np.save(output, combined)\n",
    "        print(f\"ðŸ’¾ Merged keypoints saved to {output}\")\n",
    "    else:\n",
    "        print(\"ðŸš« No keypoints merged.\")\n",
    "\n",
    "def speak(text):\n",
    "    if is_muted:\n",
    "        print(\"ðŸ”‡ Muted: Skipping speech output.\")\n",
    "        return\n",
    "    with speech_lock:\n",
    "        print(\"ðŸ”Š [TTS] Speaking now...\")\n",
    "        print(f\"ðŸ”Š [TTS Content]: {text}\")\n",
    "        engine = pyttsx3.init()\n",
    "        engine.setProperty(\"rate\", 150)\n",
    "        engine.setProperty(\"volume\", 0.9)\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "        print(\"âœ… [TTS] Speech completed.\")\n",
    "\n",
    "def toggle_mute():\n",
    "    global is_muted\n",
    "    is_muted = not is_muted\n",
    "    state = \"Muted\" if is_muted else \"Unmuted\"\n",
    "    print(f\"ðŸŽšï¸ Text-to-Speech is now {state}\")\n",
    "    mute_button.config(text=f\"TTS: {state}\")\n",
    "\n",
    "def update_sign_response(text):\n",
    "    print(f\"ðŸ“© Server replied: {text}\")\n",
    "    response_label.config(text=f\"Sign Response: {text}\")\n",
    "    gemini.append_sign_user_response(text)\n",
    "    threading.Thread(target=speak, args=(text,), daemon=True).start()\n",
    "\n",
    "def on_transcription(text):\n",
    "    global latest_spoken\n",
    "    latest_spoken = text\n",
    "    normal_label.config(text=f\"Normal: {text}\")\n",
    "    gemini.append_to_history(text)\n",
    "    paraphrased = gemini.paraphrase(text)\n",
    "    sign_label.config(text=f\"Sign-Compatible: {paraphrased}\")\n",
    "    load_and_merge_keypoints(paraphrased.split(), KEYPOINTS_FOLDER, MERGED_OUTPUT_FILE)\n",
    "\n",
    "# === Transcriber ===\n",
    "class WhisperTranscriber:\n",
    "    def __init__(self, on_text):\n",
    "        self.on_text = on_text\n",
    "        self.model = whisper.load_model(\"medium\")\n",
    "        self.CHUNK = 1024 * 4\n",
    "        self.FORMAT = pyaudio.paFloat32\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 16000\n",
    "        self.SILENCE_THRESHOLD = 0.04\n",
    "        self.SILENCE_CHUNKS = 15\n",
    "        self.audio_queue = Queue()\n",
    "        self.accumulated_audio = np.array([])\n",
    "        self.silence_counter = 0\n",
    "        self.exit_flag = threading.Event()\n",
    "        self.p = pyaudio.PyAudio()\n",
    "\n",
    "    def callback(self, in_data, frame_count, time_info, status):\n",
    "        if self.exit_flag.is_set():\n",
    "            return (None, pyaudio.paComplete)\n",
    "        audio_data = np.frombuffer(in_data, dtype=np.float32)\n",
    "        self.audio_queue.put(audio_data)\n",
    "        return (in_data, pyaudio.paContinue)\n",
    "\n",
    "    def is_speech(self, chunk):\n",
    "        return np.max(np.abs(chunk)) > self.SILENCE_THRESHOLD\n",
    "\n",
    "    def process_audio(self):\n",
    "        while not self.exit_flag.is_set():\n",
    "            if not self.audio_queue.empty():\n",
    "                chunk = self.audio_queue.get()\n",
    "                if self.is_speech(chunk):\n",
    "                    self.accumulated_audio = np.concatenate([self.accumulated_audio, chunk])\n",
    "                    self.silence_counter = 0\n",
    "                else:\n",
    "                    self.silence_counter += 1\n",
    "\n",
    "            if self.silence_counter >= self.SILENCE_CHUNKS and len(self.accumulated_audio) > 0:\n",
    "                print(\"ðŸ§  Transcribing...\")\n",
    "                write(\"temp.wav\", self.RATE, self.accumulated_audio)\n",
    "                result = self.model.transcribe(\"temp.wav\", language=\"en\", fp16=False)\n",
    "                text = result[\"text\"].strip()\n",
    "                if os.path.exists(\"temp.wav\"):\n",
    "                    os.remove(\"temp.wav\")\n",
    "                if text:\n",
    "                    print(f\"ðŸ“¢ Transcribed: {text}\")\n",
    "                    self.on_text(text)\n",
    "                self.accumulated_audio = np.array([])\n",
    "                self.silence_counter = 0\n",
    "            time.sleep(0.01)\n",
    "\n",
    "    def start(self):\n",
    "        self.stream = self.p.open(format=self.FORMAT, channels=self.CHANNELS, rate=self.RATE, input=True, frames_per_buffer=self.CHUNK, stream_callback=self.callback)\n",
    "        threading.Thread(target=self.process_audio, daemon=True).start()\n",
    "\n",
    "# === WebSocket Client ===\n",
    "class WebSocketClient:\n",
    "    def __init__(self):\n",
    "        self.loop = asyncio.new_event_loop()\n",
    "        self.ws = None\n",
    "        self.connected_event = threading.Event()  # <-- New\n",
    "        threading.Thread(target=self.run_loop, daemon=True).start()\n",
    "\n",
    "    def run_loop(self):\n",
    "        asyncio.set_event_loop(self.loop)\n",
    "        self.loop.run_until_complete(self.connect())\n",
    "\n",
    "    async def connect(self):\n",
    "        async with websockets.connect(TRANSLATION_SERVER_URI, max_size=50*1024*1024, ping_interval=None) as ws:\n",
    "            self.ws = ws\n",
    "            print(\"âœ… Connected to server.\")\n",
    "            self.connected_event.set()  # <-- Signal connection\n",
    "            while True:\n",
    "                msg = await ws.recv()\n",
    "                data = json.loads(msg)\n",
    "                if \"sign_user_message\" in data:\n",
    "                    update_sign_response(data[\"sign_user_message\"])\n",
    "\n",
    "    def send_message(self, text):\n",
    "        if self.ws:\n",
    "            with open(MERGED_OUTPUT_FILE, \"rb\") as f:\n",
    "                npy = base64.b64encode(f.read()).decode()\n",
    "            data = json.dumps({\"question\": text, \"npy\": npy})\n",
    "            asyncio.run_coroutine_threadsafe(self.ws.send(data), self.loop)\n",
    "            print(f\"ðŸ“¨ Sent: {text} + keypoints\")\n",
    "\n",
    "\n",
    "# === Initialize Connections ===\n",
    "gemini = GeminiProcessor()\n",
    "ws_client = WebSocketClient()\n",
    "\n",
    "# Wait for WebSocket connection to establish before starting\n",
    "print(\"â³ Waiting for WebSocket connection...\")\n",
    "ws_client.connected_event.wait()  # â¬…ï¸ Block until connected\n",
    "print(\"ðŸš€ WebSocket ready. Continuing...\")\n",
    "\n",
    "WhisperTranscriber(on_transcription).start()\n",
    "\n",
    "# === UI Setup ===\n",
    "root = tk.Tk()\n",
    "root.title(\"Sign Language Production UI\")\n",
    "root.geometry(\"900x600\")\n",
    "root.configure(bg=\"#1A1A2E\")\n",
    "\n",
    "frame = Frame(root, bg=\"#16213E\", padx=10, pady=10)\n",
    "frame.pack(pady=10)\n",
    "\n",
    "normal_label = Label(root, text=\"Normal: \", font=(\"Arial\", 16), bg=\"#1A1A2E\", fg=\"white\")\n",
    "normal_label.pack(pady=5)\n",
    "\n",
    "sign_label = Label(root, text=\"Sign-Compatible: \", font=(\"Arial\", 16), bg=\"#1A1A2E\", fg=\"white\")\n",
    "sign_label.pack(pady=5)\n",
    "\n",
    "response_label = Label(root, text=\"Sign Response: \", font=(\"Arial\", 16), bg=\"#1A1A2E\", fg=\"white\")\n",
    "response_label.pack(pady=5)\n",
    "\n",
    "mute_button = Button(root, text=\"TTS: Unmuted\", font=(\"Arial\", 14), bg=\"#6C3483\", fg=\"white\", command=toggle_mute)\n",
    "mute_button.pack(pady=5)\n",
    "\n",
    "send_button = Button(root, text=\"Send to Translator\", font=(\"Arial\", 14), bg=\"#3498DB\", fg=\"white\", command=lambda: ws_client.send_message(latest_spoken))\n",
    "send_button.pack(pady=10)\n",
    "\n",
    "# === Start UI ===\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
